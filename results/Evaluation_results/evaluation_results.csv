model,learning_type,avg_rouge1,avg_rouge2,avg_rougeL,avg_bleu,avg_bertscore
meta-llama_Llama-3.3-70B-Instruct-Turbo-fewshot,fewshot,0.6536213786707613,0.3420440949066112,0.39814590609119244,9.747690066938672,0.7570290565490723
meta-llama_Llama-3.3-70B-Instruct-Turbo-zeroshot,zeroshot,0.6457226407212688,0.3066935196332632,0.375312423926825,7.706299038785465,0.7425069212913513
meta-llama_Meta-Llama-3.1-405B-Instruct-Turbo-fewshot,fewshot,0.7046793562736509,0.3777909770223242,0.41036986418890525,12.915672152797425,0.7612457275390625
meta-llama_Meta-Llama-3.1-405B-Instruct-Turbo-zeroshot,zeroshot,0.6964173181559682,0.34975149163836317,0.3962326366764709,10.570530668559206,0.7469156384468079
mistralai_Mixtral-8x22B-Instruct-v0.1-fewshot,fewshot,0.6518138433232771,0.32506499076461287,0.38734174705552576,11.005072630893256,0.7459834218025208
mistralai_Mixtral-8x22B-Instruct-v0.1-zeroshot,zeroshot,0.6868036044975941,0.31219234918088307,0.38671954260726615,7.871028131337147,0.7382943034172058
