{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ace495b-80de-4d83-9c3b-12097c696e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer\n",
    "import sacrebleu\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dfc844",
   "metadata": {},
   "source": [
    "Tính điểm BLEU, ROUGE và BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c74d62a9-dcc2-4188-ad65-92a6c7d87d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn chứa file CSV kết quả\n",
    "results_dir = \"D:\\\\NLP\\\\results\"  # Thay bằng thư mục chứa file kết quả\n",
    "labels_dir = \"D:\\\\NLP\\\\NLP_Labels\"  # Thư mục chứa file nhãn gốc\n",
    "\n",
    "# Hàm load nhãn gốc\n",
    "def load_labels():\n",
    "    labels = {}\n",
    "    for i in range(1, 201):\n",
    "        label_file = os.path.join(labels_dir, f\"label-{i}.md\")\n",
    "        with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            labels[f\"output_{i}.json\"] = f.read().strip()\n",
    "    return labels\n",
    "\n",
    "# Hàm tính ROUGE\n",
    "def compute_rouge(predicted, reference):\n",
    "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "    scores = scorer.score(reference, predicted)\n",
    "    return {key: value.fmeasure for key, value in scores.items()}\n",
    "\n",
    "# Hàm tính BLEU\n",
    "def compute_bleu(predicted, reference):\n",
    "    bleu = sacrebleu.sentence_bleu(predicted, [reference])\n",
    "    return bleu.score\n",
    "\n",
    "# Hàm tính BERTScore\n",
    "def compute_bertscore(predicted_list, reference_list):\n",
    "    P, R, F1 = score(predicted_list, reference_list, lang=\"vi\", verbose=True)\n",
    "    return F1.mean().item()\n",
    "\n",
    "# Chạy đánh giá\n",
    "def main():\n",
    "    labels = load_labels()  # Load nhãn gốc\n",
    "    results = []\n",
    "\n",
    "    # Duyệt qua từng file kết quả của các mô hình\n",
    "    for result_file in os.listdir(results_dir):\n",
    "        if result_file.endswith(\".csv\"):\n",
    "            # Phân loại mô hình và phương pháp học\n",
    "            if \"zeroshot\" in result_file.lower():\n",
    "                learning_type = \"zeroshot\"\n",
    "            else:\n",
    "                learning_type = \"fewshot\"\n",
    "            model_name = result_file.replace(\".csv\", \"\").replace(\"_zero\", \"\").replace(\"_few\", \"\")\n",
    "            print(f\"Đang đánh giá mô hình: {model_name}, loại học: {learning_type}\")\n",
    "\n",
    "            # Đọc file kết quả\n",
    "            result_path = os.path.join(results_dir, result_file)\n",
    "            df = pd.read_csv(result_path)\n",
    "            \n",
    "            # Lưu kết quả đánh giá\n",
    "            model_scores = {\"model\": model_name, \"learning_type\": learning_type, \"rouge1\": [], \"rouge2\": [], \"rougeL\": [], \"bleu\": [], \"bertscore\": []}\n",
    "\n",
    "            predicted_list = []\n",
    "            reference_list = []\n",
    "\n",
    "            for _, row in df.iterrows():\n",
    "                file_name = row[\"file_name\"]\n",
    "                predicted = row[\"predicted_label\"]\n",
    "                reference = labels[file_name]\n",
    "\n",
    "                # Tính ROUGE\n",
    "                rouge_scores = compute_rouge(predicted, reference)\n",
    "                model_scores[\"rouge1\"].append(rouge_scores[\"rouge1\"])\n",
    "                model_scores[\"rouge2\"].append(rouge_scores[\"rouge2\"])\n",
    "                model_scores[\"rougeL\"].append(rouge_scores[\"rougeL\"])\n",
    "\n",
    "                # Tính BLEU\n",
    "                bleu_score = compute_bleu(predicted, reference)\n",
    "                model_scores[\"bleu\"].append(bleu_score)\n",
    "\n",
    "                # Thu thập dữ liệu cho BERTScore\n",
    "                predicted_list.append(predicted)\n",
    "                reference_list.append(reference)\n",
    "\n",
    "            # Tính BERTScore\n",
    "            bertscore = compute_bertscore(predicted_list, reference_list)\n",
    "            model_scores[\"bertscore\"] = [bertscore] * len(predicted_list)  # Gán giá trị chung cho từng hàng\n",
    "\n",
    "            # Tính trung bình của các độ đo\n",
    "            results.append({\n",
    "                \"model\": model_name,\n",
    "                \"learning_type\": learning_type,\n",
    "                \"avg_rouge1\": sum(model_scores[\"rouge1\"]) / len(model_scores[\"rouge1\"]),\n",
    "                \"avg_rouge2\": sum(model_scores[\"rouge2\"]) / len(model_scores[\"rouge2\"]),\n",
    "                \"avg_rougeL\": sum(model_scores[\"rougeL\"]) / len(model_scores[\"rougeL\"]),\n",
    "                \"avg_bleu\": sum(model_scores[\"bleu\"]) / len(model_scores[\"bleu\"]),\n",
    "                \"avg_bertscore\": model_scores[\"bertscore\"][0],  # Giá trị đã tính chung\n",
    "            })\n",
    "\n",
    "    # Lưu kết quả đánh giá tổng hợp\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(\"D:\\\\NLP\\\\results\\\\evaluation_results.csv\", index=False, encoding=\"utf-8\")\n",
    "    print(\"Kết quả đánh giá đã được lưu vào evaluation_results.csv\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cf00739-207a-4c2c-b1fa-b80c96213079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang đánh giá mô hình: meta-llama_Llama-3.3-70B-Instruct-Turbo-fewshot, loại học: fewshot\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b8c267e40c4744aced9bcef5c13d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d3f5c000aa439180784eb45f1e9d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 22.48 seconds, 8.81 sentences/sec\n",
      "Đang đánh giá mô hình: meta-llama_Llama-3.3-70B-Instruct-Turbo-zeroshot, loại học: zeroshot\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313b4ab5d4074d5fa5fd5a15a6473eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18d4d42954e413faf5ed83b95e79234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 20.55 seconds, 9.63 sentences/sec\n",
      "Đang đánh giá mô hình: meta-llama_Meta-Llama-3.1-405B-Instruct-Turbo-fewshot, loại học: fewshot\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5992af6c63490fb39dcdf481a42b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233d0aa91dbb4223a0cf421431bfc1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 27.97 seconds, 7.04 sentences/sec\n",
      "Đang đánh giá mô hình: meta-llama_Meta-Llama-3.1-405B-Instruct-Turbo-zeroshot, loại học: zeroshot\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65ec72a47e644a6bd01a3ea943c7e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb0d83a38eb42a6ac5413c985673e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 26.27 seconds, 7.54 sentences/sec\n",
      "Đang đánh giá mô hình: mistralai_Mixtral-8x22B-Instruct-v0.1-fewshot, loại học: fewshot\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080df0b7be0043c9839c52c7b5073cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbe3ca9330349cc92e1bdbdc81dad92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 26.48 seconds, 7.55 sentences/sec\n",
      "Đang đánh giá mô hình: mistralai_Mixtral-8x22B-Instruct-v0.1-zeroshot, loại học: zeroshot\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff787de3dc914738aa288e7ea227b2a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92179aa209a34dba9f453f1d6ad3705f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 22.94 seconds, 8.63 sentences/sec\n",
      "Kết quả đánh giá đã được lưu vào evaluation_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Chạy chương trình\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
